{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define the directory containing your images\n",
    "data_dir = 'Augmented1'\n",
    "\n",
    "# Define the directory where you want to store the train and test datasets\n",
    "train_dir = 'train_dir'\n",
    "test_dir = 'test_dir'\n",
    "\n",
    "# Create train and test directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Define the subcategories (classes)\n",
    "subcategories = ['Africanized Honey Bees (Killer Bees)_augmented', 'Aphids_augmented', 'Armyworms_augmented']\n",
    "\n",
    "# Define the train-test split ratio (e.g., 80% train, 20% test)\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Iterate over each subcategory\n",
    "for subcategory in subcategories:\n",
    "    # Get the list of images for the current subcategory\n",
    "    images = os.listdir(os.path.join(data_dir, subcategory))\n",
    "    # Shuffle the list of images\n",
    "    random.shuffle(images)\n",
    "    # Calculate the number of images for the train set based on the train_ratio\n",
    "    num_train = int(len(images) * train_ratio)\n",
    "    # Split the images into train and test sets\n",
    "    train_images = images[:num_train]\n",
    "    test_images = images[num_train:]\n",
    "    # Create subdirectories in train and test directories\n",
    "    os.makedirs(os.path.join(train_dir, subcategory), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, subcategory), exist_ok=True)\n",
    "    # Copy images to train directory\n",
    "    for image in train_images:\n",
    "        src = os.path.join(data_dir, subcategory, image)\n",
    "        dst = os.path.join(train_dir, subcategory, image)\n",
    "        shutil.copy(src, dst)\n",
    "    # Copy images to test directory\n",
    "    for image in test_images:\n",
    "        src = os.path.join(data_dir, subcategory, image)\n",
    "        dst = os.path.join(test_dir, subcategory, image)\n",
    "        shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 445 images belonging to 3 classes.\n",
      "Found 112 images belonging to 3 classes.\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 27s 2s/step - loss: 3.5053 - accuracy: 0.3461 - val_loss: 1.0780 - val_accuracy: 0.3482\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 24s 2s/step - loss: 1.0818 - accuracy: 0.3506 - val_loss: 1.1767 - val_accuracy: 0.3482\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 25s 2s/step - loss: 1.0711 - accuracy: 0.3775 - val_loss: 1.0275 - val_accuracy: 0.4107\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 25s 2s/step - loss: 1.0608 - accuracy: 0.4404 - val_loss: 1.0224 - val_accuracy: 0.4554\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 25s 2s/step - loss: 1.0592 - accuracy: 0.4382 - val_loss: 1.0189 - val_accuracy: 0.4821\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.0535 - accuracy: 0.4607 - val_loss: 1.0804 - val_accuracy: 0.4643\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 27s 2s/step - loss: 1.0996 - accuracy: 0.3236 - val_loss: 1.0983 - val_accuracy: 0.3304\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.0905 - accuracy: 0.3933 - val_loss: 1.0481 - val_accuracy: 0.4107\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 25s 2s/step - loss: 1.0936 - accuracy: 0.4360 - val_loss: 1.0569 - val_accuracy: 0.4375\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.0758 - accuracy: 0.4112 - val_loss: 1.0561 - val_accuracy: 0.4107\n",
      "4/4 [==============================] - 2s 425ms/step - loss: 1.0561 - accuracy: 0.4107\n",
      "Test Loss: 1.0561119318008423\n",
      "Test Accuracy: 0.4107142984867096\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "# Define directories for train and validation datasets\n",
    "train_dir = 'train_dir'\n",
    "test_dir = 'test_dir'\n",
    "\n",
    "# Define data generators for train and validation datasets\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Set the image size and batch size\n",
    "img_size = (256, 256)\n",
    "batch_size = 32\n",
    "\n",
    "# Load and augment training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')  # 3 output classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, epochs=10, validation_data=test_generator)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YASH\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 76s 4s/step - loss: 1.6304 - accuracy: 0.3265 - val_loss: 1.1285 - val_accuracy: 0.4138\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 78s 5s/step - loss: 1.3490 - accuracy: 0.3638 - val_loss: 1.0815 - val_accuracy: 0.4236\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 94s 6s/step - loss: 1.2597 - accuracy: 0.3507 - val_loss: 1.0743 - val_accuracy: 0.3990\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 80s 5s/step - loss: 1.2582 - accuracy: 0.3321 - val_loss: 1.0680 - val_accuracy: 0.4039\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 72s 4s/step - loss: 1.1952 - accuracy: 0.3955 - val_loss: 1.0691 - val_accuracy: 0.3941\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 73s 4s/step - loss: 1.1844 - accuracy: 0.3750 - val_loss: 1.0660 - val_accuracy: 0.4039\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 70s 4s/step - loss: 1.2161 - accuracy: 0.3396 - val_loss: 1.0544 - val_accuracy: 0.4729\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 76s 5s/step - loss: 1.1336 - accuracy: 0.3918 - val_loss: 1.0522 - val_accuracy: 0.4877\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 64s 4s/step - loss: 1.0948 - accuracy: 0.3843 - val_loss: 1.0489 - val_accuracy: 0.4778\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 64s 4s/step - loss: 1.1023 - accuracy: 0.3862 - val_loss: 1.0472 - val_accuracy: 0.4286\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 62s 4s/step - loss: 1.1080 - accuracy: 0.3619 - val_loss: 1.0519 - val_accuracy: 0.4729\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 61s 4s/step - loss: 1.0793 - accuracy: 0.3881 - val_loss: 1.0425 - val_accuracy: 0.4236\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 72s 4s/step - loss: 1.0554 - accuracy: 0.4534 - val_loss: 1.0428 - val_accuracy: 0.4581\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 67s 4s/step - loss: 1.0781 - accuracy: 0.3806 - val_loss: 1.0389 - val_accuracy: 0.4581\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 66s 4s/step - loss: 1.0714 - accuracy: 0.3993 - val_loss: 1.0404 - val_accuracy: 0.4433\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 68s 4s/step - loss: 1.0466 - accuracy: 0.3993 - val_loss: 1.0365 - val_accuracy: 0.4926\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 75s 4s/step - loss: 1.0462 - accuracy: 0.4384 - val_loss: 1.0334 - val_accuracy: 0.4532\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 71s 4s/step - loss: 1.0391 - accuracy: 0.4384 - val_loss: 1.0322 - val_accuracy: 0.5025\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 73s 4s/step - loss: 1.0397 - accuracy: 0.4571 - val_loss: 1.0308 - val_accuracy: 0.5025\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - 67s 4s/step - loss: 1.0445 - accuracy: 0.4198 - val_loss: 1.0319 - val_accuracy: 0.4778\n",
      "7/7 [==============================] - 20s 3s/step - loss: 1.0319 - accuracy: 0.4778\n",
      "Test Loss: 1.0318653583526611\n",
      "Test Accuracy: 0.47783252596855164\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load pre-trained ResNet50 model without including top layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add your custom classifier on top\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "model.compile(optimizer=Adam(lr=0.0001),  # Reduced learning rate\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model with more epochs\n",
    "history = model.fit(train_generator, epochs=20, validation_data=test_generator)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 445 images belonging to 3 classes.\n",
      "Found 112 images belonging to 3 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 16s 0us/step\n",
      "80150528/80134624 [==============================] - 16s 0us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 165s 12s/step - loss: 4.4900 - accuracy: 0.3798 - val_loss: 0.8536 - val_accuracy: 0.6786\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 161s 12s/step - loss: 1.3198 - accuracy: 0.4944 - val_loss: 0.7657 - val_accuracy: 0.6607\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 176s 13s/step - loss: 0.8734 - accuracy: 0.6112 - val_loss: 0.6574 - val_accuracy: 0.7679\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 177s 13s/step - loss: 0.7976 - accuracy: 0.6607 - val_loss: 0.6432 - val_accuracy: 0.7679\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 160s 12s/step - loss: 0.7913 - accuracy: 0.6360 - val_loss: 0.6012 - val_accuracy: 0.7589\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 167s 12s/step - loss: 0.7274 - accuracy: 0.6944 - val_loss: 0.5446 - val_accuracy: 0.7857\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 191s 14s/step - loss: 0.7046 - accuracy: 0.6989 - val_loss: 0.5777 - val_accuracy: 0.7589\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 167s 12s/step - loss: 0.6670 - accuracy: 0.7236 - val_loss: 0.6041 - val_accuracy: 0.7054\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 176s 13s/step - loss: 0.7455 - accuracy: 0.6719 - val_loss: 0.5963 - val_accuracy: 0.7143\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 197s 14s/step - loss: 0.7365 - accuracy: 0.6697 - val_loss: 0.5107 - val_accuracy: 0.8482\n",
      "4/4 [==============================] - 43s 11s/step - loss: 0.5107 - accuracy: 0.8482\n",
      "Test Loss: 0.5106616616249084\n",
      "Test Accuracy: 0.8482142686843872\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define directories for train and validation datasets\n",
    "train_dir = 'train_dir'\n",
    "test_dir = 'test_dir'\n",
    "\n",
    "# Define data generators for train and validation datasets\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Set the image size and batch size\n",
    "img_size = (256, 256)\n",
    "batch_size = 32\n",
    "\n",
    "# Load and augment training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load the pre-trained VGG19 model without the top layers (include_top=False)\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Freeze the pre-trained layers so they are not trained during fine-tuning\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification layers on top of the base model\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3, activation='softmax')  # 3 output classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, epochs=10, validation_data=test_generator)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
